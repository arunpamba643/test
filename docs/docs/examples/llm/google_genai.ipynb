{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use the the `google-genai` Python SDK with LlamaIndex to interact with Google GenAI models.\n",
    "\n",
    "If you're opening this Notebook on colab, you will need to install LlamaIndex ðŸ¦™ and the `google-genai` Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-google-genai llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "You will need to get an API key from [Google AI Studio](https://makersuite.google.com/app/apikey). Once you have one, you can either pass it explicity to the model, or use the `GOOGLE_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "You can call `complete` with a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a well-known figure in the tech and startup world, primarily recognized for the following:\n",
      "\n",
      "*   **Co-founder of Y Combinator (YC):** This is his most famous accomplishment. YC is a highly successful startup accelerator that has funded companies like Airbnb, Dropbox, Stripe, Reddit, and many others. He essentially pioneered a new model for early-stage startup funding and mentorship.\n",
      "\n",
      "*   **Programmer and Essayist:** Before YC, he was a successful programmer and had a startup called Viaweb, which he sold to Yahoo! in 1998 (it became Yahoo! Store). He's also a prolific essayist, writing on topics like programming, startups, design, creativity, and societal trends. His essays are highly influential and often thought-provoking.\n",
      "\n",
      "*   **Lisp Advocate:** Graham is a strong advocate for the Lisp programming language, particularly its dialect, Common Lisp. He wrote several books on Lisp programming and has used it in various projects, including Viaweb.\n",
      "\n",
      "**In summary, Paul Graham is a prominent figure known for his role in shaping the modern startup ecosystem, his insightful essays, and his passion for Lisp programming.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    # api_key=\"some key\",  # uses GOOGLE_API_KEY env var by default\n",
    ")\n",
    "\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call `chat` with a list of chat messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Ahoy there, matey! Gather 'round, ye landlubbers, and let ol' One-Eyed Pete spin ye a yarn that'll curl yer toes and make yer grog taste all the sweeter!\n",
      "\n",
      "This tale be about the infamous Pearl of Paradox, a jewel said to grant the wearer anything their heart desired. Not immortality, mind you, but the *perfect* slice of apple pie, the *exact* winning lottery numbersâ€¦ small stuff, but enough to make a pirate a king!\n",
      "\n",
      "Now, this Pearl was guarded by a beast, a kraken of epic proportions, with tentacles that could crush a galleon like a walnut and a beak sharp enough to shave yer beard clean off yer face. The kraken, they say, lived in the Whispering Abyss, a part of the sea so dark, even the stars feared to peek in.\n",
      "\n",
      "I, One-Eyed Pete, was at the helm of me ship, the *Sea Serpent's Kiss*, a vessel as sleek and deadly as a viper, with a crew that were more rum-sotted scallywags than sailors, but loyal as barnacles to a ship's hull. We'd heard whispers of the Pearl, and greed, that green-eyed devil, gnawed at our hearts.\n",
      "\n",
      "We sailed into the Whispering Abyss, the air thick as pea soup and the silence so profound, ye could hear a seagull fart a league away. Suddenly, the water began to churn, a geyser erupting from the depths! The *Sea Serpent's Kiss* rocked like a babe in a cradle.\n",
      "\n",
      "There she was! The kraken, bigger than a small island, its eyes glowing like embers in the dark. Tentacles lashed out, tearing at the ship's masts, the air filled with the splintering of wood and the screams of me crew.\n",
      "\n",
      "Now, I ain't no hero, but I ain't no coward neither. I grabbed me cutlass, sharp enough to shave a hair off a mosquito's behind, and yelled, \"For rum, riches, and a good yarn to tell!\"\n",
      "\n",
      "We fought like devils, cutlasses clashing against slimy tentacles, pistols firing into the inky blackness. But the kraken was too strong. It grabbed the *Sea Serpent's Kiss* in its grip, squeezing the life out of her.\n",
      "\n",
      "Just as I thought we were doomed, I remembered ol' Granny One-Eyed Pete's recipe for kraken repellent: a concoction of fermented mangoes, chili peppers hotter than dragon's breath, and a good dose of me own special blend of gunpowder.\n",
      "\n",
      "I dove below deck, dodging falling debris, and grabbed a barrel of the stuff. Back on deck, I climbed the highest mast, the kraken's eye looming over me like a volcano ready to erupt. With a bellow that would shame a hurricane, I heaved the barrel right into its eye!\n",
      "\n",
      "The kraken roared, a sound that shook the very seabed. It thrashed and writhed, releasing the *Sea Serpent's Kiss* and retreating back into the depths, leaving behind a cloud of pungent, mango-chili-gunpowder infused water.\n",
      "\n",
      "We were battered, bruised, and smelling like a tropical explosion, but alive! And there, floating amidst the debris, gleaming with an unearthly light, was the Pearl of Paradox.\n",
      "\n",
      "But here's the twist, mateys! I held the Pearl in me hand, felt its power, and thought, \"What do I truly desire?\" Riches? Aye, that'd be grand. But what's the fun in riches if you ain't got a good story to tell and a good crew to share it with?\n",
      "\n",
      "So, I tossed the Pearl back into the Whispering Abyss, knowing that the greatest treasure a pirate can have ain't gold or jewels, but the thrill of the adventure and the camaraderie of his crew. And that, me hearties, is worth more than all the Pearls of Paradox in the seven seas! Now, who wants another tankard of grog? Iâ€™m buyin'!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n",
    "]\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "resp = llm.chat(messages)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Support\n",
    "\n",
    "Every method supports streaming through the `stream_` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the tech world, known for his contributions to computer science, writing, and venture capital. Here's a breakdown of who he is:\n",
      "\n",
      "*   **Computer Scientist and Programmer:** He holds a Ph.D. in computer science from Harvard, specializing in Lisp programming. He is well-regarded for his work on Lisp, particularly his book \"On Lisp,\" which is considered a classic in the field. He also developed the Viaweb e-commerce platform using Lisp.\n",
      "\n",
      "*   **Entrepreneur:** Graham co-founded Viaweb in 1995, which was one of the first Software as a Service (SaaS) platforms. Viaweb allowed businesses to easily create online stores. Yahoo! acquired Viaweb in 1998, and it was renamed Yahoo! Store.\n",
      "\n",
      "*   **Writer and Essayist:** He is a prolific writer and essayist on topics ranging from technology and startups to art, philosophy, and culture. His essays are widely read and have influenced many people in the tech industry. He often writes about his experiences and perspectives on building successful companies.\n",
      "\n",
      "*   **Venture Capitalist:** He is the co-founder of Y Combinator (YC), a highly influential startup accelerator. YC has funded numerous successful startups, including Airbnb, Dropbox, Reddit, Stripe, Coinbase, and many others. Graham's approach to early-stage investing and startup mentorship has had a significant impact on the venture capital landscape.\n",
      "\n",
      "*   **Influence:** Graham's writings and Y Combinator's success have made him a highly influential figure in the startup ecosystem. He is known for his unconventional ideas and his ability to identify and nurture promising startups.\n",
      "\n",
      "In summary, Paul Graham is a computer scientist, entrepreneur, writer, and venture capitalist who has made significant contributions to the tech industry through his work on Lisp, his successful startup Viaweb, his widely read essays, and his leadership of Y Combinator."
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "\n",
    "resp = llm.stream_complete(\"Who is Paul Graham?\")\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a well-known figure in the technology and startup world. Here's a breakdown of who he is and why he's significant:\n",
      "\n",
      "*   **Computer Scientist and Hacker:** Graham holds a Ph.D. in computer science from Harvard University. He is a skilled programmer and is known for his work on Lisp, a programming language.\n",
      "\n",
      "*   **Entrepreneur:** He co-founded Viaweb in 1995, which was one of the first software-as-a-service (SaaS) companies, providing tools for building and hosting online stores. Yahoo! acquired Viaweb in 1998, and it was rebranded as Yahoo! Store.\n",
      "\n",
      "*   **Y Combinator (YC) Founder:** Graham is most famous for co-founding Y Combinator (YC) in 2005 with Jessica Livingston, Trevor Blackwell, and Robert Tappan Morris. YC is a seed accelerator that provides funding, mentorship, and networking opportunities to early-stage startups.\n",
      "\n",
      "*   **Influential Startup Advisor and Essayist:** Through YC, Graham has advised thousands of startups, including Airbnb, Dropbox, Reddit, Stripe, and many others. He is also a prolific essayist, writing on topics ranging from startups and technology to art, philosophy, and urbanism. His essays are widely read and highly influential in the startup community. His essays are available on his website: http://paulgraham.com/articles.html\n",
      "\n",
      "**In summary:** Paul Graham is a computer scientist, entrepreneur, and investor, best known as the co-founder of Y Combinator. He is a highly influential figure in the startup world, known for his insightful essays and his role in helping to launch some of the most successful tech companies of recent times."
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Who is Paul Graham?\"),\n",
    "]\n",
    "\n",
    "resp = llm.stream_chat(messages)\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Usage\n",
    "\n",
    "Every synchronous method has an async counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the tech and startup world, known for his work as a programmer, essayist, venture capitalist, and co-founder of Y Combinator. Here's a breakdown of his key contributions:\n",
      "\n",
      "*   **Programmer:** Graham holds a Ph.D. in computer science from Harvard, where he studied Lisp. He is known for his expertise in Lisp and its applications, particularly in building web applications.\n",
      "\n",
      "*   **Essayist:** Graham is a prolific and influential essayist, covering topics like startups, technology, design, programming, and life. His essays are known for their clear thinking, insightful observations, and often contrarian perspectives. Many of his essays are considered essential reading for entrepreneurs.\n",
      "\n",
      "*   **Venture Capitalist:** Graham is a co-founder of Y Combinator (YC), a highly successful startup accelerator. YC has funded many well-known companies, including Airbnb, Dropbox, Reddit, Stripe, and many others.\n",
      "\n",
      "*   **Y Combinator (YC):** Graham's most significant impact has likely been through YC. He helped pioneer a new model for startup funding and incubation, providing early-stage companies with seed funding, mentorship, and a supportive community. YC's Demo Day, where startups present their work to investors, has become a major event in the tech industry.\n",
      "\n",
      "In summary, Paul Graham is a highly influential figure in the tech world, known for his technical expertise, insightful writing, and significant contributions to the startup ecosystem through Y Combinator."
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "\n",
    "resp = await llm.astream_complete(\"Who is Paul Graham?\")\n",
    "async for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Paul Graham is a prominent figure in the world of computer science, startups, and writing. Here's a breakdown of who he is and why he's notable:\n",
      "\n",
      "*   **Computer Scientist and Hacker:** Graham is a computer scientist with a Ph.D. in Computer Science from Harvard. He's known for his work on Lisp programming language and for co-founding Viaweb.\n",
      "\n",
      "*   **Co-founder of Viaweb (Yahoo! Store):** Viaweb, which he co-founded in 1995, was one of the first software-as-a-service (SaaS) e-commerce platforms. Yahoo! acquired it in 1998 and rebranded it as Yahoo! Store.\n",
      "\n",
      "*   **Co-founder of Y Combinator:** In 2005, Graham co-founded Y Combinator (YC), a highly influential startup accelerator that has funded and mentored numerous successful companies.\n",
      "\n",
      "*   **Startup Guru/Advisor:** Through Y Combinator, Graham became a leading figure in the startup world, offering advice and guidance to countless founders on topics ranging from product development to fundraising.\n",
      "\n",
      "*   **Essayist and Author:** Graham is a prolific writer, known for his essays on startups, programming, technology, and broader topics like curiosity, cities, and art. His essays are widely read and discussed in the tech community. Some of his famous essays include \"Hackers & Painters,\" \"Do Things That Don't Scale,\" and \"How to Start a Startup.\" He has also authored the book \"Hackers & Painters: Big Ideas from the Age of Silicon.\"\n",
      "\n",
      "*   **Known for his Contrarian Views:** Graham often expresses opinions that challenge conventional wisdom, which has both earned him respect and sparked controversy.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Who is Paul Graham?\"),\n",
    "]\n",
    "\n",
    "resp = await llm.achat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Support\n",
    "\n",
    "By providing the `region` and `project_id` parameters (either through environment variables or directly), you can use an Anthropic model through Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "!export GOOGLE_GENAI_USE_VERTEXAI=true\n",
    "!export GOOGLE_CLOUD_PROJECT='your-project-id'\n",
    "!export GOOGLE_CLOUD_LOCATION='us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "# or set the parameters directly\n",
    "llm = GoogleGenAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    vertexai_config={\"project\": \"your-project-id\", \"location\": \"us-central1\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Modal Support\n",
    "\n",
    "Using `ChatMessage` objects, you can pass in images and text to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg -O image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The image contains four wooden dice. Each die has black dots indicating the numbers. The dice are arranged on a dark surface.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, TextBlock, ImageBlock\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        blocks=[\n",
    "            ImageBlock(path=\"image.jpg\"),\n",
    "            TextBlock(text=\"What is in this image?\"),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Prediction\n",
    "\n",
    "LlamaIndex provides an intuitive interface for converting any Anthropic LLMs into a structured LLM through `structured_predict` - simply define the target Pydantic class (can be nested), and given a prompt, we extract out the desired object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.bridge.pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class MenuItem(BaseModel):\n",
    "    \"\"\"A menu item in a restaurant.\"\"\"\n",
    "\n",
    "    course_name: str\n",
    "    is_vegetarian: bool\n",
    "\n",
    "\n",
    "class Restaurant(BaseModel):\n",
    "    \"\"\"A restaurant with name, city, and cuisine.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    city: str\n",
    "    cuisine: str\n",
    "    menu_items: List[MenuItem]\n",
    "\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "prompt_tmpl = PromptTemplate(\n",
    "    \"Generate a restaurant in a given city {city_name}\"\n",
    ")\n",
    "\n",
    "# Option 1: Use `as_structured_llm`\n",
    "restaurant_obj = (\n",
    "    llm.as_structured_llm(Restaurant)\n",
    "    .complete(prompt_tmpl.format(city_name=\"Miami\"))\n",
    "    .raw\n",
    ")\n",
    "# Option 2: Use `structured_predict`\n",
    "# restaurant_obj = llm.structured_predict(Restaurant, prompt_tmpl, city_name=\"Miami\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='BurgerPlace' city='Miami' cuisine='American' menu_items=[MenuItem(course_name='burger', is_vegetarian=False)]\n"
     ]
    }
   ],
   "source": [
    "print(restaurant_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Prediction with Streaming\n",
    "\n",
    "Any LLM wrapped with `as_structured_llm` supports streaming through `stream_chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'San Francisco',\n",
      " 'cuisine': 'Italian',\n",
      " 'menu_items': [{'course_name': 'Pasta', 'is_vegetarian': False}],\n",
      " 'name': \"Tony's\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/xwsz_3yj4ln1gvkxhyddbvvw0000gn/T/ipykernel_47921/1885953561.py:11: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  pprint(partial_output.raw.dict())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Restaurant(name=\"Tony's\", city='San Francisco', cuisine='Italian', menu_items=[MenuItem(course_name='Pasta', is_vegetarian=False)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "input_msg = ChatMessage.from_str(\"Generate a restaurant in San Francisco\")\n",
    "\n",
    "sllm = llm.as_structured_llm(Restaurant)\n",
    "stream_output = sllm.stream_chat([input_msg])\n",
    "for partial_output in stream_output:\n",
    "    clear_output(wait=True)\n",
    "    pprint(partial_output.raw.dict())\n",
    "    restaurant_obj = partial_output.raw\n",
    "\n",
    "restaurant_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool/Function Calling\n",
    "\n",
    "Google GenAI supports direct tool/function calling through the API. Using LlamaIndex, we can implement some core agentic tool calling patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from datetime import datetime\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "def get_current_time(timezone: str) -> dict:\n",
    "    \"\"\"Get the current time\"\"\"\n",
    "    return {\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"timezone\": timezone,\n",
    "    }\n",
    "\n",
    "\n",
    "# uses the tool name, any type annotations, and docstring to describe the tool\n",
    "tool = FunctionTool.from_defaults(fn=get_current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply do a single pass to call the tool and get the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '2025-03-07 22:58:45', 'timezone': 'America/New_York'}\n"
     ]
    }
   ],
   "source": [
    "resp = llm.predict_and_call([tool], \"What is the current time in New York?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use lower-level APIs to implement an agentic tool-calling loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling get_current_time with {'timezone': 'America/New_York'}\n",
      "Tool output:  {'time': '2025-03-07 22:58:46', 'timezone': 'America/New_York'}\n",
      "Final response:  The current time in New York is 2025-03-07 22:58:46.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    ChatMessage(role=\"user\", content=\"What is the current time in New York?\")\n",
    "]\n",
    "tools_by_name = {t.metadata.name: t for t in [tool]}\n",
    "\n",
    "resp = llm.chat_with_tools([tool], chat_history=chat_history)\n",
    "tool_calls = llm.get_tool_calls_from_response(\n",
    "    resp, error_on_no_tool_call=False\n",
    ")\n",
    "\n",
    "if not tool_calls:\n",
    "    print(resp)\n",
    "else:\n",
    "    while tool_calls:\n",
    "        # add the LLM's response to the chat history\n",
    "        chat_history.append(resp.message)\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.tool_name\n",
    "            tool_kwargs = tool_call.tool_kwargs\n",
    "\n",
    "            print(f\"Calling {tool_name} with {tool_kwargs}\")\n",
    "            tool_output = tool.call(**tool_kwargs)\n",
    "            print(\"Tool output: \", tool_output)\n",
    "            chat_history.append(\n",
    "                ChatMessage(\n",
    "                    role=\"tool\",\n",
    "                    content=str(tool_output),\n",
    "                    # most LLMs like Anthropic, OpenAI, etc. need to know the tool call id\n",
    "                    additional_kwargs={\"tool_call_id\": tool_call.tool_id},\n",
    "                )\n",
    "            )\n",
    "\n",
    "            resp = llm.chat_with_tools([tool], chat_history=chat_history)\n",
    "            tool_calls = llm.get_tool_calls_from_response(\n",
    "                resp, error_on_no_tool_call=False\n",
    "            )\n",
    "    print(\"Final response: \", resp.message.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "gemini.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
