{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf7d63d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/managed/vectaraDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0855d0",
   "metadata": {},
   "source": [
    "# Vectara Managed Index\n",
    "In this notebook we are going to show how to use [Vectara](https://vectara.com) with LlamaIndex.\n",
    "\n",
    "[Vectara](https://vectara.com/) is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications. \n",
    "\n",
    "Vectara provides an end-to-end managed service for Retrieval Augmented Generation or [RAG](https://vectara.com/grounded-generation/), which includes:\n",
    "\n",
    "1. An integrated API for processing input data, including text extraction from documents and ML-based chunking.\n",
    "\n",
    "2. The state-of-the-art [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) embeddings model. Each text chunk is encoded into a vector embedding using Boomerang, and stored in the Vectara internal knowledge (vector+text) store. Thus, when using Vectara with LlamaIndex you do not need to call a separate embedding model - this happens automatically within the Vectara backend.\n",
    "\n",
    "3. A query service that automatically encodes the query into embeddings and retrieves the most relevant text segmentsthrough [hybrid search](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) and a variety of [reranking](https://docs.vectara.com/docs/api-reference/search-apis/reranking) strategies, including a [multilingual reranker](https://docs.vectara.com/docs/learn/vectara-multi-lingual-reranker), [maximal marginal relevance (MMR) reranker](https://docs.vectara.com/docs/learn/mmr-reranker), [user-defined function reranker](https://docs.vectara.com/docs/learn/user-defined-function-reranker), and a [chain reranker](https://docs.vectara.com/docs/learn/chain-reranker) that provides a way to chain together multiple reranking methods to achieve better control over the reranking, combining the strengths of various reranking methods.\n",
    "\n",
    "4. An option to create a [generative summary](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview) with a wide selection of LLM summarizers (including Vectara's [Mockingbird](https://vectara.com/blog/mockingbird-is-a-rag-specific-llm-that-beats-gpt-4-gemini-1-5-pro-in-rag-output-quality/), trained specifically for RAG-based tasks), based on the retrieved documents, including citations.\n",
    "\n",
    "See the [Vectara API documentation](https://docs.vectara.com/docs/) for more information on how to use the API.\n",
    "\n",
    "The main benefits of using Vectara RAG-as-a-service to build your application are:\n",
    "* **Accuracy and Quality**: Vectara provides an end-to-end platform that focuses on eliminating hallucinations, reducing bias, and safeguarding copyright integrity.\n",
    "* **Security**: Vectara's platform provides acess control--protecting against prompt injection attacks--and meets SOC2 and HIPAA compliance.\n",
    "* **Explainability**: Vectara makes it easy to troubleshoot bad results by clearly explaining rephrased queries, LLM prompts, retrieved results, and agent actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2497c",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-indices-managed-vectara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b201796-4463-4ec4-b537-d855a384878c",
   "metadata": {},
   "source": [
    "To get started with Vectara, [sign up](https://vectara.com/integrations/llamaindex) (if you haven't already) and follow our [quickstart guide](https://docs.vectara.com/docs/quickstart) to create a corpus and an API key.\n",
    "\n",
    "Once you have these, you can provide them as environment variables `VECTARA_CORPUS_KEY`, and `VECTARA_API_KEY`. Make sure your API key has both query and index permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "## RAG with LlamaIndex and Vectara\n",
    "\n",
    "There are a few ways you can index your data into Vectara, including:\n",
    "1. With the `from_documents()` or `insert_file()` methods of `VectaraIndex`\n",
    "2. Uploading files directly in the [Vectara console](https://console.vectara.com/)\n",
    "3. Using Vectara's [file upload](https://docs.vectara.com/docs/rest-api/upload-file) or [document index](https://docs.vectara.com/docs/rest-api/create-corpus-document) APIs\n",
    "4. Using [vectara-ingest](https://github.com/vectara/vectara-ingest), an open source crawler/indexer project\n",
    "5. Using one of our ingest integration partners like Airbyte, Unstructured or DataVolo.\n",
    "\n",
    "For this purpose, we will use a simple set of small documents, so using `VectaraIndex` directly for the ingest is good enough.\n",
    "\n",
    "Let's ingest the \"AI bill of rights\" document into our new corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154dd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai-bill-of-rights.pdf'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.indices.managed.vectara import VectaraIndex\n",
    "import requests\n",
    "\n",
    "url = \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\"\n",
    "response = requests.get(url)\n",
    "local_path = \"ai-bill-of-rights.pdf\"\n",
    "with open(local_path, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "index = VectaraIndex()\n",
    "index.insert_file(\n",
    "    local_path, metadata={\"name\": \"AI bill of rights\", \"year\": 2022}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "### Running single queries with Vectara Query Engine\n",
    "Now that we've uploaded the document (or if documents have been uploaded previously) we can go and ask questions directly in LlamaIndex. This activates Vectara's RAG pipeline. \n",
    "\n",
    "To use Vectara's internal LLM for summarization, make sure you specify `summary_enabled=True` when you generate the Query engine. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb174ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What are the risks of AI?\",\n",
    "    \"What should we do to prevent bad actors from using AI?\",\n",
    "    \"What are the benefits?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f7133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The risks of AI include biased data and discriminatory outcomes, opaque decision-making processes, and lack of public trust and understanding of algorithmic systems [1]. These risks can have significant impacts on individuals, communities, and organizations, and can lead to harm, including image-based abuse, which disproportionately affects women [7]. AI systems can also incorrectly penalize individuals, such as drivers, for events beyond their control [7]. To mitigate these risks, ongoing transparency, value-sensitive and participatory design, explanations designed for relevant stakeholders, and public consultation are necessary [1]. Additionally, industry is providing innovative solutions to mitigate risks, including risk assessments, auditing mechanisms, and documentation procedures specific to model assessments [2]. The National Institute of Standards and Technology has also developed an AI Risk Management Framework to help identify and mitigate risks [3].'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qe = index.as_query_engine(\n",
    "    n_sentences_before=1,\n",
    "    n_sentences_after=1,\n",
    "    summary_enabled=True,\n",
    "    summary_prompt_name=\"mockingbird-1.0-2024-07-16\",\n",
    ")\n",
    "qe.query(questions[0]).response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c464a9a-0386-43d5-b074-c7ee8eb1d3fe",
   "metadata": {},
   "source": [
    "If you want the response to be returned in streaming mode, simply set `streaming=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eafb4c-4fe7-4e81-b588-dd83979917fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risks of AI include biased data and discriminatory outcomes, opaque decision-making processes, and lack of public trust and understanding of algorithmic systems [1]. These risks can have significant impacts on individuals, communities, and organizations, and can lead to harm, including image-based abuse, which disproportionately affects women [7]. AI systems can also incorrectly penalize individuals, such as drivers, for events beyond their control [7]. To mitigate these risks, ongoing transparency, value-sensitive and participatory design, explanations designed for relevant stakeholders, and public consultation are necessary [1]. Additionally, industry is providing innovative solutions to mitigate risks, including risk assessments, auditing mechanisms, and documentation procedures specific to model assessments [2]. The National Institute of Standards and Technology has also developed an AI Risk Management Framework to help identify and mitigate risks [3].ate risks [3]."
     ]
    }
   ],
   "source": [
    "qe = index.as_query_engine(\n",
    "    n_sentences_before=1,\n",
    "    n_sentences_after=1,\n",
    "    summary_enabled=True,\n",
    "    summary_prompt_name=\"mockingbird-1.0-2024-07-16\",\n",
    "    streaming=True,\n",
    ")\n",
    "response = qe.query(questions[0])\n",
    "\n",
    "for chunk in response.response_gen:\n",
    "    print(chunk.delta or \"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e74c56-2fd3-4e0d-a387-d6088766ce2c",
   "metadata": {},
   "source": [
    "### Using Vectara Chat\n",
    "\n",
    "Vectara also supports a simple chat mode. In this mode the chat history is maintained by Vectara and so you don't have to worry about it. To use it simple call `as_chat_engine`.\n",
    "\n",
    "(Chat mode always uses Vectara's summarization so you don't have to explicitly specify `summary_enabled=True` like before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb45dc-b02b-4c5f-9f93-28d0e20d6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = index.as_chat_engine(n_sentences_before=1, n_sentences_after=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907248f-ff80-41fa-98e9-b1e4bb1b1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the risks of AI?\n",
      "\n",
      "Response: The risks of AI include potential biases in data leading to discriminatory outcomes, opaque decision-making processes, lack of public trust, and understanding of algorithmic systems. Mitigation strategies involve ongoing transparency, participatory design, explanations for stakeholders, and public consultation to ensure safety and efficacy. Risks also encompass the impact on individuals' rights, opportunities, and communities, as well as the potential for misuse of AI systems. Additionally, there are concerns about image-based abuse disproportionately affecting women and instances where AI systems incorrectly penalize individuals due to errors or external factors beyond their control.\n",
      "\n",
      "Question: What should we do to prevent bad actors from using AI?\n",
      "\n",
      "Response: To prevent bad actors from using AI, we should implement comprehensive measures. These include adhering to principles such as ensuring AI is lawful, respectful, accurate, safe, secure, and transparent [2]. Additionally, entities must follow privacy and security best practices to prevent data leaks and unauthorized access [3]. It is crucial to evaluate, protect against, and redress harms of automated systems at both individual and community levels [5]. Furthermore, ongoing transparency, participatory design, and public consultation are essential for the future design of critical AI systems [4]. Non-profits and companies should conduct audits and impact assessments to identify algorithmic discrimination and ensure equitable use and design of automated systems [6]. By incorporating these practices and principles, we can mitigate the risks associated with bad actors utilizing AI technologies.\n",
      "\n",
      "Question: What are the benefits?\n",
      "\n",
      "Response: The benefits of AI include the potential to build innovative infrastructure, improve customer service through faster responses, and provide solutions in various sectors such as agriculture, healthcare, and disaster prediction. AI can enhance decision-making processes, streamline operations, and contribute to the overall efficiency of different industries. Additionally, AI can help in protecting people's rights and ensuring the responsible development and integration of technology within communities [1] [4] [5]. The principles outlined in the promotion of trustworthy AI emphasize the importance of lawful, purposeful, safe, and accountable AI systems, ensuring they align with national values and are transparent and regularly monitored [6]. Ultimately, AI has the transformative potential to positively impact lives while mitigating potential harms through responsible and thoughtful implementation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(f\"Question: {q}\\n\")\n",
    "    response = ce.chat(q).response\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105809b-efea-4937-b6a3-e3de8986aa8c",
   "metadata": {},
   "source": [
    "Of course streaming works as well with Chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc0885-01a4-4569-864d-0eb8bbc70eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = index.as_chat_engine(\n",
    "    n_sentences_before=1, n_sentences_after=1, streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44797ff-d23f-4d6a-9839-82aec6040af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence will not rule the government. The government has established principles and guidelines for the ethical use of AI, ensuring that it is used responsibly, lawfully, and in alignment with the nation's values. These principles emphasize safety, accountability, transparency, and effectiveness in the deployment of AI within the federal government [1] [2]. Additionally, there are specific considerations for sensitive areas like law enforcement and national security, where special requirements and oversight mechanisms are in place to safeguard against misuse [3]. The government is focused on promoting equity, fairness, civil rights, and racial justice through the use of AI, guided by principles that protect the American public and uphold democratic values [5]. The establishment of councils and offices dedicated to AI advancement within government agencies further demonstrates a structured and controlled approach to AI integration, ensuring it serves the public interest [4] [7]."
     ]
    }
   ],
   "source": [
    "response = ce.stream_chat(\"Will artificial intelligence rule the government?\")\n",
    "for chunk in response.chat_stream:\n",
    "    print(chunk.delta or \"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52fe86d-b0d5-4520-bac2-df9324a5eacc",
   "metadata": {},
   "source": [
    "### Agentic RAG\n",
    "\n",
    "Vectara also has its own package, [vectara-agentic](https://github.com/vectara/py-vectara-agentic), built on top of many features from LlamaIndex to easily implement agentic RAG applications. It allows you to create your own AI assistant with RAG query tools and other custom tools, such as making API calls to retrieve information from financial websites. You can find the full documentation for vectara-agentic [here](https://vectara.github.io/vectara-agentic-docs/).\n",
    "\n",
    "Let's create a ReAct Agent with a single RAG tool using vectara-agentic (to create a ReAct agent, specify `VECTARA_AGENTIC_AGENT_TYPE` as `\"REACT\"` in your environment).\n",
    "\n",
    "Vectara does not yet have an LLM capable of acting as an agent for planning and tool use, so we will need to use another LLM as the driver of the agent resoning.\n",
    "\n",
    "In this demo, we are using OpenAI's GPT4o. Please make sure you have `OPENAI_API_KEY` defined in your environment or specify another LLM with the corresponding key (for the full list of supported LLMs, check out our [documentation](https://vectara.github.io/vectara-agentic-docs/introduction.html#try-it-yourself) for setting up your environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0d504-bc72-4dfc-8cdf-83b8aa69206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U vectara-agentic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee674bf5-fccb-42cb-8499-77aad14fc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to set up observer (No module named 'phoenix.otel'), ignoring\n",
      "> Running step ed1749a3-91c3-4477-8415-cf5646402b73. Step input: What are the risks of AI? What are the benefits? Compare and contrast and provide a summary with arguments for and against from experts.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: query_ai\n",
      "Action Input: {'query': 'risks and benefits of AI, expert opinions'}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query warning(s) exceeded_max_input_length_fcs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: \n",
      "                    Response: '''According to expert opinions, the risks of AI include biased data and discriminatory outcomes, opaque decision-making processes, and lack of public trust and understanding of algorithmic systems [1]. To mitigate these risks, experts emphasize the importance of ongoing transparency, value-sensitive and participatory design, explanations designed for relevant stakeholders, and public consultation [1]. Additionally, industry is providing innovative solutions to mitigate risks to the safety and efficacy of AI systems, including risk assessments, auditing mechanisms, and documentation procedures [3]. The National Institute of Standards and Technology (NIST) is developing a risk management framework to better manage risks posed to individuals, organizations, and society by AI [3]. Furthermore, the White House Office of Science and Technology Policy has led a year-long process to seek input from people across the country on the issue of algorithmic and data-driven harms and potential remedies [4].'''\n",
      "                    References:\n",
      "                    [1]: CreationDate='1663695035'; Producer='iLovePDF'; Title='Blueprint for an AI Bill of Rights'; Creator='Adobe Illustrator 26.3 (Macintosh)'; ModDate='1664808078'; name='AI bill of rights'; year='2022'; framework='llama_index'; title='Blueprint for an AI Bill of Rights'.\n",
      "[3]: CreationDate='1663695035'; Producer='iLovePDF'; Title='Blueprint for an AI Bill of Rights'; Creator='Adobe Illustrator 26.3 (Macintosh)'; ModDate='1664808078'; name='AI bill of rights'; year='2022'; framework='llama_index'; title='Blueprint for an AI Bill of Rights'.\n",
      "[4]: CreationDate='1663695035'; Producer='iLovePDF'; Title='Blueprint for an AI Bill of Rights'; Creator='Adobe Illustrator 26.3 (Macintosh)'; ModDate='1664808078'; name='AI bill of rights'; year='2022'; framework='llama_index'; title='Blueprint for an AI Bill of Rights'.\n",
      "\n",
      "                \n",
      "\u001b[0m> Running step 319a9cb0-3d54-4709-ba22-4f8987ecdb6d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The risks and benefits of AI are widely discussed among experts, and there are compelling arguments on both sides.\n",
      "\n",
      "**Risks of AI:**\n",
      "1. **Bias and Discrimination**: AI systems can perpetuate and even amplify biases present in the data they are trained on, leading to discriminatory outcomes. This is a significant concern in areas like hiring, law enforcement, and lending.\n",
      "2. **Opaque Decision-Making**: Many AI systems, particularly those based on deep learning, operate as \"black boxes,\" making it difficult to understand how decisions are made. This lack of transparency can erode trust.\n",
      "3. **Public Trust and Understanding**: There is often a gap in understanding how AI systems work, which can lead to mistrust and fear among the public.\n",
      "4. **Safety and Efficacy**: Ensuring that AI systems are safe and effective is a challenge, particularly as they become more complex and autonomous.\n",
      "\n",
      "To address these risks, experts recommend transparency, participatory design, stakeholder-specific explanations, and public consultation. Industry solutions include risk assessments, auditing mechanisms, and documentation procedures. The National Institute of Standards and Technology (NIST) is also developing a risk management framework to manage these risks effectively.\n",
      "\n",
      "**Benefits of AI:**\n",
      "1. **Efficiency and Productivity**: AI can automate routine tasks, leading to increased efficiency and productivity in various sectors, from manufacturing to healthcare.\n",
      "2. **Innovation**: AI drives innovation by enabling new products and services, such as personalized medicine and autonomous vehicles.\n",
      "3. **Data Analysis**: AI excels at analyzing large datasets, uncovering patterns and insights that would be impossible for humans to detect.\n",
      "4. **Improved Decision-Making**: By providing data-driven insights, AI can enhance decision-making processes in fields like finance, healthcare, and logistics.\n",
      "\n",
      "In summary, while AI presents significant risks, particularly related to bias, transparency, and trust, it also offers substantial benefits in terms of efficiency, innovation, and data analysis. Balancing these risks and benefits requires careful consideration, ongoing transparency, and robust risk management frameworks, as highlighted by experts and initiatives like the Blueprint for an AI Bill of Rights [1][3][4].\n",
      "\u001b[0mTime taken: 20.221316814422607\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The risks and benefits of AI are widely discussed among experts, and there are compelling arguments on both sides.\n",
       "\n",
       "**Risks of AI:**\n",
       "1. **Bias and Discrimination**: AI systems can perpetuate and even amplify biases present in the data they are trained on, leading to discriminatory outcomes. This is a significant concern in areas like hiring, law enforcement, and lending.\n",
       "2. **Opaque Decision-Making**: Many AI systems, particularly those based on deep learning, operate as \"black boxes,\" making it difficult to understand how decisions are made. This lack of transparency can erode trust.\n",
       "3. **Public Trust and Understanding**: There is often a gap in understanding how AI systems work, which can lead to mistrust and fear among the public.\n",
       "4. **Safety and Efficacy**: Ensuring that AI systems are safe and effective is a challenge, particularly as they become more complex and autonomous.\n",
       "\n",
       "To address these risks, experts recommend transparency, participatory design, stakeholder-specific explanations, and public consultation. Industry solutions include risk assessments, auditing mechanisms, and documentation procedures. The National Institute of Standards and Technology (NIST) is also developing a risk management framework to manage these risks effectively.\n",
       "\n",
       "**Benefits of AI:**\n",
       "1. **Efficiency and Productivity**: AI can automate routine tasks, leading to increased efficiency and productivity in various sectors, from manufacturing to healthcare.\n",
       "2. **Innovation**: AI drives innovation by enabling new products and services, such as personalized medicine and autonomous vehicles.\n",
       "3. **Data Analysis**: AI excels at analyzing large datasets, uncovering patterns and insights that would be impossible for humans to detect.\n",
       "4. **Improved Decision-Making**: By providing data-driven insights, AI can enhance decision-making processes in fields like finance, healthcare, and logistics.\n",
       "\n",
       "In summary, while AI presents significant risks, particularly related to bias, transparency, and trust, it also offers substantial benefits in terms of efficiency, innovation, and data analysis. Balancing these risks and benefits requires careful consideration, ongoing transparency, and robust risk management frameworks, as highlighted by experts and initiatives like the Blueprint for an AI Bill of Rights [1][3][4]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vectara_agentic.agent import Agent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "agent = Agent.from_corpus(\n",
    "    tool_name=\"query_ai\",\n",
    "    data_description=\"AI regulations\",\n",
    "    assistant_specialty=\"artificial intelligence\",\n",
    "    vectara_reranker=\"mmr\",\n",
    "    vectara_rerank_k=50,\n",
    "    vectara_summary_num_results=5,\n",
    "    vectara_summarizer=\"mockingbird-1.0-2024-07-16\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response = agent.chat(\n",
    "    \"What are the risks of AI? What are the benefits? Compare and contrast and provide a summary with arguments for and against from experts.\"\n",
    ")\n",
    "\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
